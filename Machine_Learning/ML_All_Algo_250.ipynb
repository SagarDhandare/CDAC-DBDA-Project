{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a70ed8-0a13-4b37-850d-19be9ff65e4d",
   "metadata": {},
   "source": [
    "## Brain Tumour Detection using Machine Learning Algorithms like Random Forest Classifier, Gradient Boosting Classifier, XGBoost Classifier, Support Vector Machine and comparing their predictions and repeatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc07290-c836-4d22-a7bc-dea29bfb052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required Libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e18db99c-bed7-4f62-994e-75cfeca6c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset:\n",
    "df = pd.read_csv('Zernike_Moments_YN_250.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f313caa9-9752-4e3e-bd10-509396a8fac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.042958</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.037135</td>\n",
       "      <td>0.100063</td>\n",
       "      <td>0.059319</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.048925</td>\n",
       "      <td>0.071876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>0.013368</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.131339</td>\n",
       "      <td>0.056533</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.028023</td>\n",
       "      <td>0.057654</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>0.067312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019978</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.034376</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.030357</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>0.019903</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.066687</td>\n",
       "      <td>0.052518</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.023271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.020199</td>\n",
       "      <td>0.013016</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.016715</td>\n",
       "      <td>0.039403</td>\n",
       "      <td>0.030387</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.016265</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018493</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.015955</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>0.016589</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.021282</td>\n",
       "      <td>0.035434</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.044254</td>\n",
       "      <td>0.019344</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6    \\\n",
       "0  0.31831  0.042958  0.010156  0.037135  0.100063  0.059319  0.013843   \n",
       "1  0.31831  0.131339  0.056533  0.043445  0.028023  0.057654  0.002174   \n",
       "2  0.31831  0.066687  0.052518  0.019200  0.011847  0.011882  0.002686   \n",
       "3  0.31831  0.016715  0.039403  0.030387  0.006614  0.015393  0.010426   \n",
       "4  0.31831  0.025001  0.021282  0.035434  0.016394  0.044254  0.019344   \n",
       "\n",
       "        7         8         9    ...       280       281       282       283  \\\n",
       "0  0.028088  0.048925  0.071876  ...  0.016465  0.014127  0.012504  0.013368   \n",
       "1  0.015591  0.030578  0.067312  ...  0.019978  0.010809  0.034376  0.012750   \n",
       "2  0.010105  0.013947  0.023271  ...  0.007538  0.016812  0.007287  0.016342   \n",
       "3  0.003477  0.016265  0.003031  ...  0.018493  0.021749  0.009007  0.015955   \n",
       "4  0.009703  0.005623  0.012174  ...  0.005710  0.008091  0.007286  0.007084   \n",
       "\n",
       "        284       285       286       287       288  289  \n",
       "0  0.010715  0.010428  0.012418  0.008424  0.015612  YES  \n",
       "1  0.030357  0.005956  0.019903  0.006420  0.033680  YES  \n",
       "2  0.005139  0.020199  0.013016  0.021188  0.002611  YES  \n",
       "3  0.018917  0.004270  0.014429  0.007866  0.016589  YES  \n",
       "4  0.004886  0.012870  0.013376  0.007630  0.016100  YES  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 records:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea950b84-85b1-4c5b-80b4-f94076cba7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 290)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the number of row and Columns:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2c8777-efc6-42e5-aca5-1568adce6297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YES    154\n",
       "NO      96\n",
       "Name: 289, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target data:\n",
    "df[289].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a564b3ed-0edf-4ebb-a7fa-84166b7f9097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.4 % of the patients who has Brain Tumour.\n",
      "61.6 % of the patients who do not have Brain Tumour.\n"
     ]
    }
   ],
   "source": [
    "# To determine how many patients have Brain Tumour and how many do not(Target data):\n",
    "print(round(df[289].value_counts()[1]/len(df) * 100,2), '% of the patients who has Brain Tumour.')\n",
    "print(round(df[289].value_counts()[0]/len(df) * 100,2), '% of the patients who do not have Brain Tumour.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db2b6b1c-9201-49b4-8351-d98e87c8673a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEXCAYAAABCjVgAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZpElEQVR4nO3deZhddZ3n8fcHoiiiDTQFIotBRRtwxZJxa5sWFVzD2KMG2zEqGkZxwVa27lZQmxEVF0akR1QguICotND6KCIutCOCYd9EUBQCgQRoZRFDB77zxzk5XIqqpFLm3htz36/nqafq/H5n+VYR7uf+zvK7qSokSQJYb9gFSJLWHoaCJKljKEiSOoaCJKljKEiSOoaCJKljKGiokvwmyXuHXceqJJmdpJKM92Hfhya5tGf5+CTfWtPHaffdt99D6wZDQX2TZIskRyb5VZJlSa5P8p0kLxl2bSu0L5Arvv6Q5NdJvpLkuRNWvQ7YErhwmvtdnbA7Avib6Vc9PUl+lOSoCc2r9Xto9BgK6osks4Hzgd2Bg4EnAy8Avg383+FVNqm30LxQ7gDsDdwNnJVk/xUrVNU9VXVjVS1fUwdNsl6S9avqjqq6ZU3td2X68Xto3WIoqF+OBgKMV9XJVXVlVV1RVUcBT5lqoyT/kOTiJHe2I4vPJ9m4p/8vknwxyZIkf2zf2e/X079Pkl+2fUuTnJ5k1ipq/V37QvnbqvphVb0BOBz4cJLHtfu932mXJA9K8n+S3NCOgq5Lcnjb9yPg0cDHVoxC2vY3JLkjyUva00V3AztMPH3U87v8c5Kb2m2OS/LQnr4HjAJ6TzslOZ5m9LFvz0ho9mSnj5I8L8k57d/spiSfTPLgCcc6Osn/TnJz+7c/Isl6Peu8sv3vdleSW5P8OMkWq/i7ay1kKGiNS7IpsAdwVFXdMbG/qv5zJZvfC+wH7AS8FtgF+HRP/78ATwJeBvwV8Cbg+va448BngA8AT6AZmXx3hr/Gx2n+/9hziv53Av8dmAtsD7wGuLLteyWwCPggzQhky57tHgL8M7APsCPw2yn2/zc04bkb8HfAi4CPrEb97wLOBo7rqeG6iSsl2Qr4DnAB8DSakdJewIcnrPr3wHLg2cDbaf4bvabdxyOBk4AFNKOt5wFfXI1atRZZ1TsoaSYeRzNKuGJ1N6yqT/Us/ibJAcCpSeZV1b0078AvqKpzV6zTs/62wJ3AaVV1O80L7kWrXz5U1S1JlgCPmWKVRwO/BP6jmgnErgV+2m57a5J7gNur6sYJ260PvKOqzlvRkGSy/d8DvLEN1UuTHAh8IcnBVXXnNOr/fZK7gT/01jDJsd4GLAbe1v59r0hyEPDZJO+rqj+0611eVe9vf/5lkrfQBNaJwKOABwFfr6oVIfeAkY/+PDhSUD9M+io3rQ2T5yc5I8miJLcDpwAPBh7ZrvKvwKuTXNSewui9QHsGTRBck+TLSeYlefhMa6H5PaaaMfJ44Kk0L5CfSfLS3tMpK7Gc6V3kvXjCKOtsmr/DY6ex7erYATi7DYQVftIe63G99UzY7gZg8/bni4Dv04TXN5K8NcnYGq5TA2IoqB+uonkx3WF1NkryaJoL0VcArwKeTnN6CJoXKarqOzTv0o8ANgO+neS4tu92YGfg1TTv3A8GfpHkUav7CyTZDBgDfj1Zf1WdD8wG/pHm/6MFwBnTCIZlVXXP6tYziXt5YPg+aAb7WVnw9bb/1yR960Fz8Zrm9NaLaMJjb+CqJFNeO9Lay1DQGldVtwKnA29PstHE/t4LxxOM07z4v7uqzq6qX9Kcmpi4/5ur6ovtBeG9gXlJNmj7llfVD6pqxR1PD6O5/rC63kPzwnvqVCtU1e1V9bWqeivwUuD53Pfu+m6aU0Uz9aQkD+tZfma7z1+1y0u5/7UKeOAF/OnUcDnwrAlh9twJx1qlapxdVR8AnkEzknjNdLfX2sNrCuqXt9GcY1+Y5H007yAD/C3NO/htJ9nmKpo3KvslOYXmhXC/3hWSfJDmVtfLaP79vhL4dVUtS/IymtMrZwG3tsd6OKu+trFxe7F0xemZecDrgQOq6urJNkjyDzTn4i+keRf9WuA2mgvM0Fzr+OskX6IZHdy8ihommgUc2/6+j6K5G+pzPdcTfgB8KskraC5w7wNsw/2vsfwG2CXN7cF30PxNJjqa5m98dJIjaa6hHE5zk8AfJln/AZI8k+ai/unATTQXrLehCRz9mTEU1BdVdU2SnWlOr3wE2Aq4heb88z5TbHNxkncBB9LcZfRT4L3AV3tWWwYcBmwH/BH4GfDytu93NHcLvR/YkOad7pur6j9WUe7neva9uN3nrlV11kq2uR3Yn+bOo6K5e+fFPS+k7wc+29awAat/neXHNMH3w/Z3+QZwQE//sTQjoWPb5aOBf6M5pbbCETSntS4HHkrzN7ufqro+yYuBj9EE3O+Ar9D8d5uu3wPPAd4BbExzl9OHqupLq7EPrSXiJ69JklbwmoIkqWMoSJI6hoIkqdO3UEhybDtHyqUT2t+R5MoklyX5aE/7wUmubvt271ddkqSp9fPuo+OBo4ATVjQk+VtgDvDk9hbCzdv2HWnmkNmJ5va77yd5/Koe8tlss81q9uzZ/alektZR55133s1VNelT530Lhao6q70/utdbgcOralm7zpK2fQ5wUtt+TZKraSZCO3tlx5g9ezYLFy5cs4VL0jouyVQTMQ78msLjaR7oOaedWvcZbftW3H8Gx0VtmyRpgAb98NosYBOaJ1WfAZyc5DFM/mDPpA9QJJkPzAfYdtvJHoqVJM3UoEcKi4BT2nlSzqWZW2aztn2bnvW2ppk75QGq6piqGq+q8bExJ2KUpDVp0KHwTZpJw0jyeJq5Zm4GTgPmJtkgyXY0UwecO9VOJEn90bfTR0lOBHYFNkuyCDiEZp6WY3PfRxHOaz+g5LIkJ9PM0bIc2HcNTS8sSVoNf9ZzH42Pj5d3H0nS6klyXlWNT9bnE82SpI6hIEnqGAqSpM7If8jO0/c/YdUraeSc97HXD7sEaSgcKUiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKnTt1BIcmySJe3nMU/se2+SSrJZT9vBSa5OcmWS3ftVlyRpav0cKRwP7DGxMck2wAuBa3vadgTmAju12xydZP0+1iZJmkTfQqGqzgJunaTrk8ABQPW0zQFOqqplVXUNcDWwS79qkyRNbqDXFJK8Ari+qi6a0LUVcF3P8qK2TZI0QAP7OM4kGwL/BLxosu5J2mqSNpLMB+YDbLvttmusPknSYEcKjwW2Ay5K8htga+D8JI+kGRls07Pu1sANk+2kqo6pqvGqGh8bG+tzyZI0WgYWClV1SVVtXlWzq2o2TRDsXFU3AqcBc5NskGQ7YHvg3EHVJklq9POW1BOBs4EnJFmUZO+p1q2qy4CTgcuB7wL7VtU9/apNkjS5vl1TqKq9VtE/e8LyYcBh/apHkrRqPtEsSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkTj8/o/nYJEuSXNrT9rEkv0hycZJ/S7JxT9/BSa5OcmWS3ftVlyRpav0cKRwP7DGh7QzgiVX1ZOCXwMEASXYE5gI7tdscnWT9PtYmSZpE30Khqs4Cbp3Q9r2qWt4u/gzYuv15DnBSVS2rqmuAq4Fd+lWbJGlyw7ym8CbgO+3PWwHX9fQtatseIMn8JAuTLFy6dGmfS5Sk0TKUUEjyT8By4MsrmiZZrSbbtqqOqarxqhofGxvrV4mSNJJmDfqASeYBLwN2q6oVL/yLgG16VtsauGHQtUnSqBvoSCHJHsCBwCuq6g89XacBc5NskGQ7YHvg3EHWJknq40ghyYnArsBmSRYBh9DcbbQBcEYSgJ9V1f+qqsuSnAxcTnNaad+quqdftUmSJte3UKiqvSZp/sJK1j8MOKxf9UiSVs0nmiVJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktTpWygkOTbJkiSX9rRtmuSMJFe13zfp6Ts4ydVJrkyye7/qkiRNrZ8jheOBPSa0HQScWVXbA2e2yyTZEZgL7NRuc3SS9ftYmyRpEn0Lhao6C7h1QvMcYEH78wJgz572k6pqWVVdA1wN7NKv2iRJkxv0NYUtqmoxQPt987Z9K+C6nvUWtW0PkGR+koVJFi5durSvxUrSqFlbLjRnkraabMWqOqaqxqtqfGxsrM9lSdJoGXQo3JRkS4D2+5K2fRGwTc96WwM3DLg2SRp5gw6F04B57c/zgFN72ucm2SDJdsD2wLkDrk2SRt6sfu04yYnArsBmSRYBhwCHAycn2Ru4FngVQFVdluRk4HJgObBvVd3Tr9okSZPrWyhU1V5TdO02xfqHAYf1qx5J0qr1LRQk/Wmu/eCThl2C1kLbvv+Svu5/bbn7SJK0FjAUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEmdaYVCkjOn0yZJ+vO20ieakzwE2JBm/qJNuG+K60cAj+pzbZKkAVvVNBf7APvRBMB53BcKtwGf6V9ZkqRhWGkoVNWRwJFJ3lFVnx5QTZKkIZnWhHhV9ekkzwZm925TVSf0qS5J0hBMKxSSfBF4LHAhsOJzDgowFCRpHTLdqbPHgR2ratLPTZYkrRum+5zCpcAj+1mIJGn4pjtS2Ay4PMm5wLIVjVX1ir5UJUkaiumGwqFr8qBJ3g28mea6xCXAG2meh/gqzcXs3wCvrqr/XJPHlSSt3HTvPvrxmjpgkq2Ad9Jco7grycnAXGBH4MyqOjzJQcBBwIFr6riSpFWb7jQXtye5rf36Y5J7ktz2Jxx3FvDQJLNoRgg3AHOABW3/AmDPP2H/kqQZmO5I4eG9y0n2BHaZyQGr6vokRwDXAncB36uq7yXZoqoWt+ssTrL5ZNsnmQ/MB9h2221nUoIkaQozmiW1qr4JPH8m27ZzKM0BtqOZPuNhSV63Gsc+pqrGq2p8bGxsJiVIkqYw3YfXXtmzuB7NcwszfWbhBcA1VbW03fcpwLOBm5Js2Y4StgSWzHD/kqQZmu7dRy/v+Xk5zd1Bc2Z4zGuBZybZkOb00W7AQuBOYB5wePv91BnuX5I0Q9O9pvDGNXXAqjonydeB82kC5gLgGGAj4OQke9MEx6vW1DElSdMz3dNHWwOfBp5Dc9roJ8C7qmrRTA5aVYcAh0xoXkYzapAkDcl0LzQfB5xGc2F4K+Df2zZJ0jpkuqEwVlXHVdXy9ut4wFt/JGkdM91QuDnJ65Ks3369Driln4VJkgZvuqHwJuDVwI3AYuB/0MxXJElah0z3ltQPAfNWTFCXZFPgCJqwkCStI6Y7Unhy74ylVXUr8LT+lCRJGpbphsJ67fQUQDdSmO4oQ5L0Z2K6L+wfB37aPnRWNNcXDutbVZKkoZjuE80nJFlIMwlegFdW1eV9rUySNHDTPgXUhoBBIEnrsBlNnS1JWjcZCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkzlBCIcnGSb6e5BdJrkjyrCSbJjkjyVXt901WvSdJ0po0rJHCkcB3q+qvgKcAVwAHAWdW1fbAme2yJGmABh4KSR4BPA/4AkBV3V1VvwPmAAva1RYAew66NkkadcMYKTwGWAocl+SCJJ9P8jBgi6paDNB+33yyjZPMT7IwycKlS5cOrmpJGgHDCIVZwM7Av1bV04A7WY1TRVV1TFWNV9X42NhYv2qUpJE0jFBYBCyqqnPa5a/ThMRNSbYEaL8vGUJtkjTSBh4KVXUjcF2SJ7RNu9FMyX0aMK9tmwecOujaJGnUDesjNd8BfDnJg4FfA2+kCaiTk+wNXAu8aki1SdLIGkooVNWFwPgkXbsNuBRJUg+faJYkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVJnaKGQZP0kFyT5Vru8aZIzklzVft9kWLVJ0qga5kjhXcAVPcsHAWdW1fbAme2yJGmAhhIKSbYGXgp8vqd5DrCg/XkBsOeAy5KkkTeskcKngAOAe3vatqiqxQDt980n2zDJ/CQLkyxcunRp3wuVpFEy8FBI8jJgSVWdN5Ptq+qYqhqvqvGxsbE1XJ0kjbZZQzjmc4BXJHkJ8BDgEUm+BNyUZMuqWpxkS2DJEGqTpJE28JFCVR1cVVtX1WxgLvCDqnodcBowr11tHnDqoGuTpFG3Nj2ncDjwwiRXAS9slyVJAzSM00edqvoR8KP251uA3YZZjySNurVppCBJGjJDQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUGXgoJNkmyQ+TXJHksiTvats3TXJGkqva75sMujZJGnXDGCksB95TVTsAzwT2TbIjcBBwZlVtD5zZLkuSBmjgoVBVi6vq/Pbn24ErgK2AOcCCdrUFwJ6Drk2SRt1QrykkmQ08DTgH2KKqFkMTHMDmU2wzP8nCJAuXLl06sFolaRQMLRSSbAR8A9ivqm6b7nZVdUxVjVfV+NjYWP8KlKQRNJRQSPIgmkD4clWd0jbflGTLtn9LYMkwapOkUTaMu48CfAG4oqo+0dN1GjCv/XkecOqga5OkUTdrCMd8DvA/gUuSXNi2/SNwOHBykr2Ba4FXDaE2SRppAw+FqvoJkCm6dxtkLZKk+/OJZklSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHXWulBIskeSK5NcneSgYdcjSaNkrQqFJOsDnwFeDOwI7JVkx+FWJUmjY60KBWAX4Oqq+nVV3Q2cBMwZck2SNDJmDbuACbYCrutZXgT8t94VkswH5reLdyS5ckC1jYLNgJuHXcTaIEfMG3YJuj//ba5wSNbEXh49VcfaFgqT/bZ1v4WqY4BjBlPOaEmysKrGh12HNJH/NgdnbTt9tAjYpmd5a+CGIdUiSSNnbQuFnwPbJ9kuyYOBucBpQ65JkkbGWnX6qKqWJ3k7cDqwPnBsVV025LJGiafltLby3+aApKpWvZYkaSSsbaePJElDZChIkjqGwohI4ydJXtzT9uok301yT5ILe74OavtfluSCJBcluTzJPsP7DTQKklSSj/csvzfJoT3L85P8ov06N8lzh1LoOsxrCiMkyROBrwFPo7mQfyGwB3BRVW00Yd0HAb8FdqmqRUk2AGZXlQ8Lqm+S/BFYDDyjqm5O8l5go6o6NMnLgA8Au7d9OwPfpPk3euPwql63OFIYIVV1KfDvwIHAIcAJVfWrKVZ/OM3dabe02y4zEDQAy2nuNHr3JH0HAvtX1c0AVXU+sADYd3DlrfvWqltSNRAfAM4H7gZWPCH60CQX9qzz4ar6apLTgN8mORP4FnBiVd070Go1ij4DXJzkoxPadwLOm9C2EHBOkjXIUBgxVXVnkq8Cd1TVsrb5rqp66iTrvjnJk4AXAO8FXgi8YVC1ajRV1W1JTgDeCdy1itXDhKlw9Kfx9NFourf9WqWquqSqPkkTCH/X16qk+3wK2Bt4WE/b5cDTJ6y3c9uuNcRQ0KSSbJRk156mp9JceJb6rqpuBU6mCYYVPgp8JMlfAiR5Ks3I9ehB17cu8/SR4IHXFL4LHAYckOSzNEP4O/HUkQbr48DbVyxU1WlJtgJ+mqSA24HXVdXiYRW4LvKWVElSx9NHkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoaB1UpK/7Jn19cYk1/csP3gNH2vjJG9bSf8dq7GvQ9tJ4Fbn+NPev7QqPqegdVJV3ULzwB3t1Mt3VNURq9ouyayqWr6ah9sYeBs+RKV1gCMFjYwkb0ny8/bzIb6RZMO2/fgkn0jyQ5onZh+b5Gftuh/sfSeeZP+2/eIkH2ibDwce245CPjbNWl6e5Jz28yq+n2SLnu6nJPlBkquSvGUVx+7d55ZJzmrruDTJX8/k76TRZiholJxSVc+oqqcAV3D/KRQeD7ygqt4DHAkcWVXPAG5YsUKSFwHbA7vQjEKenuR5wEHAr6rqqVW1/zRr+QnwzKp6GnAScEBP35OBlwLPAt6f5FErOXav1wKnt5MbPoXm8zKk1eLpI42SJyb5F5rTPRsBp/f0fa2q7ml/fhawZ/vzV4AVp51e1H5d0C5vRPNCfe0Matka+GqSLYEHA9f09J1aVXcBd7Wjl12A505x7LN6tvs5cGz7AUnfrKoLZ1CXRpwjBY2S44G3V9WTaD5X4iE9fXdOY/vQfNbEU9uvx1XVF2ZYy6eBo9pa9plQy8S5Z2o6x66qs4DnAdcDX0zy+hnWphFmKGiUPBxY3L6T/vuVrPcz7psmfG5P++nAm5JsBJBkqySb00zM9vDVrOUvaF684YEfEjMnyUPa2UB3pRkBTHXsTpJHA0uq6nPAF2imlZZWi6ePNEreB5xDMwX4JUz9Qr4f8KUk7wG+DfweoKq+l2QH4OwkAHfQzNL5qyT/L8mlwHcmua6wYZJFPcufAA4FvpbkepoQ2q6n/9z2uNsCH6qqG4AbJjs2sKRnu12B/ZP8V9vvSEGrzVlSpQnau5LuqqpKMhfYq6rmDLsuaRAcKUgP9HTgqDRvyX8HvGm45UiD40hBktTxQrMkqWMoSJI6hoIkqWMoSJI6hoIkqfP/AXyVT1NOZbS9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the target distribution:\n",
    "sns.countplot(x = df[289])\n",
    "plt.title('Class Distributions', fontsize=14)\n",
    "plt.xlabel(\"Target Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9b738d-f8ea-465c-98fa-e4b54a3f844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the whole dataset:\n",
    "df = df.sample(frac=1, random_state=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a901295-172c-4ca8-93bc-72805b59b498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.042827</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.010871</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>0.017326</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.191613</td>\n",
       "      <td>0.161184</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.123063</td>\n",
       "      <td>0.075663</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.013368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.026577</td>\n",
       "      <td>0.023802</td>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.021180</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.090509</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.055604</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.013105</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>0.030085</td>\n",
       "      <td>0.041330</td>\n",
       "      <td>0.019037</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.047149</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.032980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.021806</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.025076</td>\n",
       "      <td>0.017768</td>\n",
       "      <td>0.014713</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6    \\\n",
       "0  0.31831  0.042712  0.010810  0.016246  0.013723  0.025530  0.004094   \n",
       "1  0.31831  0.076294  0.191613  0.161184  0.019352  0.069739  0.123063   \n",
       "2  0.31831  0.090509  0.003142  0.055604  0.028385  0.004643  0.014882   \n",
       "3  0.31831  0.011740  0.007222  0.005579  0.002402  0.005769  0.002898   \n",
       "4  0.31831  0.012451  0.034418  0.030085  0.041330  0.019037  0.011416   \n",
       "\n",
       "        7         8         9    ...       280       281       282       283  \\\n",
       "0  0.011501  0.042827  0.005350  ...  0.002403  0.010871  0.018847  0.012027   \n",
       "1  0.075663  0.012809  0.013368  ...  0.020009  0.026577  0.023802  0.018322   \n",
       "2  0.026152  0.010947  0.010543  ...  0.005868  0.015268  0.008084  0.022066   \n",
       "3  0.003528  0.002909  0.001386  ...  0.010026  0.017193  0.002296  0.014789   \n",
       "4  0.047149  0.018054  0.032980  ...  0.019599  0.010177  0.021806  0.005711   \n",
       "\n",
       "        284       285       286       287       288  289  \n",
       "0  0.004450  0.018338  0.017326  0.001737  0.011057   NO  \n",
       "1  0.020650  0.012505  0.012780  0.011807  0.021180  YES  \n",
       "2  0.001968  0.022256  0.012318  0.025472  0.001286  YES  \n",
       "3  0.004481  0.016137  0.013105  0.008306  0.006268   NO  \n",
       "4  0.006053  0.008584  0.025076  0.017768  0.014713   NO  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After shuffling:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "251091d5-ce47-4ef2-aeaa-8ecc324d72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical values of Target feature into numerical:\n",
    "df[289].replace(['YES','NO'], [1,0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951da750-1119-4a23-b8fe-eb75acda2ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.042827</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.010871</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>0.017326</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.191613</td>\n",
       "      <td>0.161184</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.123063</td>\n",
       "      <td>0.075663</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.013368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.026577</td>\n",
       "      <td>0.023802</td>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.021180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.090509</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.055604</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.013105</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>0.030085</td>\n",
       "      <td>0.041330</td>\n",
       "      <td>0.019037</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.047149</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.032980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.021806</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.025076</td>\n",
       "      <td>0.017768</td>\n",
       "      <td>0.014713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6    \\\n",
       "0  0.31831  0.042712  0.010810  0.016246  0.013723  0.025530  0.004094   \n",
       "1  0.31831  0.076294  0.191613  0.161184  0.019352  0.069739  0.123063   \n",
       "2  0.31831  0.090509  0.003142  0.055604  0.028385  0.004643  0.014882   \n",
       "3  0.31831  0.011740  0.007222  0.005579  0.002402  0.005769  0.002898   \n",
       "4  0.31831  0.012451  0.034418  0.030085  0.041330  0.019037  0.011416   \n",
       "\n",
       "        7         8         9    ...       280       281       282       283  \\\n",
       "0  0.011501  0.042827  0.005350  ...  0.002403  0.010871  0.018847  0.012027   \n",
       "1  0.075663  0.012809  0.013368  ...  0.020009  0.026577  0.023802  0.018322   \n",
       "2  0.026152  0.010947  0.010543  ...  0.005868  0.015268  0.008084  0.022066   \n",
       "3  0.003528  0.002909  0.001386  ...  0.010026  0.017193  0.002296  0.014789   \n",
       "4  0.047149  0.018054  0.032980  ...  0.019599  0.010177  0.021806  0.005711   \n",
       "\n",
       "        284       285       286       287       288  289  \n",
       "0  0.004450  0.018338  0.017326  0.001737  0.011057    0  \n",
       "1  0.020650  0.012505  0.012780  0.011807  0.021180    1  \n",
       "2  0.001968  0.022256  0.012318  0.025472  0.001286    1  \n",
       "3  0.004481  0.016137  0.013105  0.008306  0.006268    0  \n",
       "4  0.006053  0.008584  0.025076  0.017768  0.014713    0  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After Converting Target feature to numerical:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22a3f3a-526e-4db2-988d-2f665d9ae5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Independent and Dependent features:\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b0ed54-674f-43b2-9986-84b49700a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test spilt:\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c013fdde-517b-4030-a5ef-05f11150803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 289)\n",
      "(50, 289)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape after train-test split:\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d79d31-49f6-4eca-9657-c829474cfcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributions:\n",
      "\n",
      "Train Set\n",
      "1    123\n",
      "0     77\n",
      "Name: 289, dtype: int64\n",
      "\n",
      "Test Set\n",
      "1    31\n",
      "0    19\n",
      "Name: 289, dtype: int64\n",
      "\n",
      "In Percentage:\n",
      "\n",
      "Train Set\n",
      "1    61.5\n",
      "0    38.5\n",
      "Name: 289, dtype: float64\n",
      "\n",
      "Test Set\n",
      "1    62.0\n",
      "0    38.0\n",
      "Name: 289, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Train-Test data distribution\n",
    "print(\"Distributions:\")\n",
    "print(\"\\nTrain Set\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nTest Set\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(\"\\nIn Percentage:\")\n",
    "print(\"\\nTrain Set\")\n",
    "print((y_train.value_counts()/ len(y_train))*100)\n",
    "print(\"\\nTest Set\")\n",
    "print((y_test.value_counts()/ len(y_test))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445107c8-201a-4abb-ae4d-97d4dcac350a",
   "metadata": {},
   "source": [
    "### Build classification models using Random Forest Classifier, Gradient Boosting Classifier, XGBoost classifier and Support Vector Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa20b83e-d96e-460b-8d02-84f613875b7b",
   "metadata": {},
   "source": [
    "### Using Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02ff3f9e-608e-45f4-a8f9-cce8b2c2d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Object of XGBoost Classifier:\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "527ad36f-f2ed-4184-a6b3-20c8305df59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using k-fold cross validation for 5 - folds:\n",
    "y_train_rf_K = cross_val_predict(rf, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34319cd6-e481-4cae-93df-4a4027209ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 78.0 %\n",
      "Precision : 0.77\n",
      "Recall    : 0.91\n",
      "F1_Score  : 0.83\n",
      "\n",
      "Confusion Matrix :\n",
      "[[ 43  34]\n",
      " [ 11 112]]\n"
     ]
    }
   ],
   "source": [
    "# For K-fold cross Validation\n",
    "print(\"Accuracy  :\", round(accuracy_score(y_train, y_train_rf_K),2)*100,\"%\")\n",
    "print(\"Precision :\", round(precision_score(y_train, y_train_rf_K),2))\n",
    "print(\"Recall    :\", round(recall_score(y_train, y_train_rf_K),2))\n",
    "print(\"F1_Score  :\", round(f1_score(y_train, y_train_rf_K),2))\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confusion_matrix(y_train, y_train_rf_K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63d1e95c-1861-400e-bf32-c089b08402de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Training data:\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d775486-8a81-458d-8335-3f17e96f8810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data:\n",
    "y_pred_rf = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af7080a4-1c12-4ff0-8ade-396b50acfe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 78.0 %\n",
      "Precision : 0.74\n",
      "Recall    : 1.0\n",
      "f1_Score  : 0.85\n",
      "\n",
      "Confusion Matrix :\n",
      "[[ 8 11]\n",
      " [ 0 31]]\n"
     ]
    }
   ],
   "source": [
    "# For Random Forest\n",
    "print(\"Accuracy  :\", round(accuracy_score(y_test, y_pred_rf), 2)*100,\"%\")\n",
    "print(\"Precision :\", round(precision_score(y_test, y_pred_rf), 2))\n",
    "print(\"Recall    :\", round(recall_score(y_test, y_pred_rf), 2))\n",
    "print(\"f1_Score  :\", round(f1_score(y_test, y_pred_rf), 2))\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3801d-af16-4bd8-bc26-5df96c8b54f2",
   "metadata": {},
   "source": [
    "### Using Gradient Boosting Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f13b2f97-8464-4db1-97c2-dd6e813a4ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Object of GradientBoostingClassifier:\n",
    "gbm = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d50816c5-da88-4946-90bb-6b9570e03237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation for 5 - folds:\n",
    "y_train_gbm_K = cross_val_predict(gbm, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96efbf13-4fa1-416e-a4f5-d442dabbb7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 80.0 %\n",
      "Precision : 0.8\n",
      "Recall    : 0.89\n",
      "f1_Score  : 0.84\n",
      "\n",
      "Confusion Matrix :\n",
      "[[ 49  28]\n",
      " [ 13 110]]\n"
     ]
    }
   ],
   "source": [
    "# For K-fold cross Validation:\n",
    "print(\"Accuracy  :\", round(accuracy_score(y_train, y_train_gbm_K), 2)*100,\"%\")\n",
    "print(\"Precision :\", round(precision_score(y_train, y_train_gbm_K), 2))\n",
    "print(\"Recall    :\", round(recall_score(y_train, y_train_gbm_K), 2))\n",
    "print(\"f1_Score  :\", round(f1_score(y_train, y_train_gbm_K), 2))\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confusion_matrix(y_train, y_train_gbm_K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60621d58-673c-4e4a-8690-92875f175a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Training data:\n",
    "gbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bd526b7-fa42-4fa5-9721-d0734b60b647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicting the test data:\n",
    "y_pred_gbm = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "451bff8f-2a31-48ac-84bd-eddb1c38be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 74.0 %\n",
      "Precision : 0.76\n",
      "Recall    : 0.84\n",
      "f1_Score  : 0.8\n",
      "\n",
      "Confusion Matrix :\n",
      "[[11  8]\n",
      " [ 5 26]]\n"
     ]
    }
   ],
   "source": [
    "# For Gradient Boosting:\n",
    "print(\"Accuracy  :\", round(accuracy_score(y_test, y_pred_gbm), 2)*100,\"%\")\n",
    "print(\"Precision :\", round(precision_score(y_test, y_pred_gbm), 2))\n",
    "print(\"Recall    :\", round(recall_score(y_test, y_pred_gbm), 2))\n",
    "print(\"f1_Score  :\", round(f1_score(y_test, y_pred_gbm), 2))\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_pred_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba665079-5b1d-4b78-80c4-c3f7aa12b3d6",
   "metadata": {},
   "source": [
    "### Using XGBoost Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "195c5081-1207-459c-97f3-2397d9b7b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Object of XGBoost Classifier:\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "208bca63-f43e-4ee3-9829-b31fe314e503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:02:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:02:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:02:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:02:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\LENOVO\\Anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:02:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation for 5 - folds:\n",
    "y_train_xgb_K = cross_val_predict(xgb, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e505c718-fd81-4c5f-86b2-5bcc6020c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 79.0 %\n",
      "Precision : 0.8\n",
      "Recall    : 0.89\n",
      "f1_Score  : 0.84\n",
      "\n",
      "Confusion Matrix :\n",
      "[[ 49  28]\n",
      " [ 14 109]]\n"
     ]
    }
   ],
   "source": [
    "# For K-fold cross Validation\n",
    "print(\"Accuracy  :\", round(accuracy_score(y_train, y_train_xgb_K), 2)*100,\"%\")\n",
    "print(\"Precision :\", round(precision_score(y_train, y_train_xgb_K), 2))\n",
    "print(\"Recall    :\", round(recall_score(y_train, y_train_xgb_K), 2))\n",
    "print(\"f1_Score  :\", round(f1_score(y_train, y_train_xgb_K), 2))\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confusion_matrix(y_train, y_train_xgb_K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "579cb718-978e-40f4-a990-7eebb2f90f58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:02:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Training data:\n",
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b095ef56-e76c-4927-acb3-30921933e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data:\n",
    "y_pred_xgb = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04a4c421-10fe-4551-9b82-f96ded800de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 86.0 %\n",
      "Precision : 0.88\n",
      "Recall    : 0.9\n",
      "f1_Score  : 0.89\n",
      "\n",
      "Confusion Matrix :\n",
      "[[15  4]\n",
      " [ 3 28]]\n"
     ]
    }
   ],
   "source": [
    "# For XGBoost Classifier:\n",
    "print(\"Accuracy  :\", round(accuracy_score(y_test, y_pred_xgb), 2)*100,\"%\")\n",
    "print(\"Precision :\", round(precision_score(y_test, y_pred_xgb), 2))\n",
    "print(\"Recall    :\", round(recall_score(y_test, y_pred_xgb), 2))\n",
    "print(\"f1_Score  :\", round(f1_score(y_test, y_pred_xgb), 2))\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffba58-b0f0-440d-87df-4d57eae4b959",
   "metadata": {},
   "source": [
    "### Using Support Vector Machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bea208c3-a808-429c-b8b3-0fca053d6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Object of Support Vector Machine:\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f894880-f03c-436a-96a1-275ea010e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation for 5 - folds:\n",
    "y_train_svm_K = cross_val_predict(svm, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e955ce08-3215-4f86-b9e9-acaacc964bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 66.0 %\n",
      "Precision : 0.66\n",
      "Recall    : 0.94\n",
      "f1_Score  : 0.77\n",
      "\n",
      "Confusion Matrix :\n",
      "[[ 16  61]\n",
      " [  7 116]]\n"
     ]
    }
   ],
   "source": [
    "# For K-fold cross Validation:\n",
    "print(\"Accuracy  :\", round(accuracy_score(y_train, y_train_svm_K), 2)*100,\"%\")\n",
    "print(\"Precision :\", round(precision_score(y_train, y_train_svm_K), 2))\n",
    "print(\"Recall    :\", round(recall_score(y_train, y_train_svm_K), 2))\n",
    "print(\"f1_Score  :\", round(f1_score(y_train, y_train_svm_K), 2))\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confusion_matrix(y_train, y_train_svm_K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bc541fa-8eb7-4766-8692-3faec03230d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Training data:\n",
    "svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ead7284-ff9e-4877-a4b1-eb73094c5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data:\n",
    "y_pred_svm = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "200f9b5c-e2f1-4f57-8623-5b5578ab7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 68.0 %\n",
      "Precision : 0.66\n",
      "Recall : 1.0\n",
      "f1_Score : 0.79\n",
      "\n",
      "Confusion Matrix :\n",
      "[[ 3 16]\n",
      " [ 0 31]]\n"
     ]
    }
   ],
   "source": [
    "# For SVM:\n",
    "print(\"Accuracy :\", round(accuracy_score(y_test, y_pred_svm), 2)*100,\"%\")\n",
    "print(\"Precision :\", round(precision_score(y_test, y_pred_svm), 2))\n",
    "print(\"Recall :\", round(recall_score(y_test, y_pred_svm), 2))\n",
    "print(\"f1_Score :\", round(f1_score(y_test, y_pred_svm), 2))\n",
    "print(\"\\nConfusion Matrix :\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee6fdf8-cde3-490f-b603-6f35b7d1751e",
   "metadata": {},
   "source": [
    "### Conclusion, Comparing the performance of all the models (Random Forest, GBM, XGBOOST and SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d2061-bf3e-40eb-b258-2ce9d3abe4a0",
   "metadata": {},
   "source": [
    "- Accuracy of Random Forest : **78%**\n",
    "- Accuracy of GBM   : **74%**\n",
    "- Accuracy of XGBoost   : **86%**\n",
    "- Accuracy of SVM   : **68%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbea79-a1f4-4996-a726-6715f2b93b14",
   "metadata": {},
   "source": [
    "- Precision of Random Forest : **0.74**\n",
    "- Precision of GBM   : **0.76**\n",
    "- Precision of XGBoost   : **0.88**\n",
    "- Precision of SVM   : **0.66**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866904a-12d0-4520-bc35-0d22e11a2e2b",
   "metadata": {},
   "source": [
    "- Recall of Random Forest : **1.0**\n",
    "- Recall of GBM   : **0.84**\n",
    "- Recall of XGBoost   : **0.90**\n",
    "- Recall of SVM   : **1.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f6b51-0ce5-4ef4-84ec-31ab7ba9c0ae",
   "metadata": {},
   "source": [
    "- F1-Score of Random Forest : **0.85**\n",
    "- F1-Score of GBM   : **0.80**\n",
    "- F1-Score of XGBoost   : **0.89**\n",
    "- F1-Score of SVM   : **0.79**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbade9d-7fa2-413c-903b-189dedab2d81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
